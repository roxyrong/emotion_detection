{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQyIdFsO2p0iiCqQ8YmJtk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roxyrong/emotion_detection/blob/main/Data_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from google.cloud import storage\n",
        "auth.authenticate_user()\n",
        "client = storage.Client()\n",
        "\n",
        "import math\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display"
      ],
      "metadata": {
        "id": "X5Z9WVVb_-wK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tFHkKmUw_5M8"
      },
      "outputs": [],
      "source": [
        "# === connect to SAVEE dataset\n",
        "bucket = client.get_bucket('savee')\n",
        "# === list the paths for all audio data\n",
        "blobs = list(bucket.list_blobs(prefix='AudioData/'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Create Empty List\n",
        "paths, labels, data = [], [], []\n",
        "\n",
        "# === Loop audio files\n",
        "for audio in blobs:\n",
        "  # === convert to string\n",
        "  file_path = str(audio).replace(\"<Blob: savee, AudioData/\",\"\")\n",
        "  # === filter out txt file\n",
        "  if \"txt\" not in file_path:\n",
        "    # === Label Processing\n",
        "    label = file_path.split('.')[0]\n",
        "    if label[3] == 'a':\n",
        "        labels.append('a')\n",
        "    elif label[3] == 'd':\n",
        "        labels.append('d')\n",
        "    elif label[3] == 'f':\n",
        "        labels.append('f')\n",
        "    elif label[3] == 'h':\n",
        "        labels.append('h')\n",
        "    elif label[3] == 'n':\n",
        "        labels.append('n')\n",
        "    elif label[3] == 's':\n",
        "        if label[4] == 'sa':\n",
        "            labels.append('sa')\n",
        "        else:\n",
        "            labels.append('su')\n",
        "\n",
        "    # === Duration Processing\n",
        "    file_path = file_path.split(\",\")[0]\n",
        "    file_path = 'AudioData/' + file_path\n",
        "    blob = bucket.blob(file_path)\n",
        "    blob.download_to_filename(\"audios\")\n",
        "\n",
        "    # === Path Processing\n",
        "    paths.append(file_path)\n",
        "\n",
        "    # === Data Loading\n",
        "    y, sr = librosa.load('audios')\n",
        "    data.append(y)\n",
        "\n",
        "# === Create a dataframe to store\n",
        "df_savee = pd.DataFrame({'data': data, 'path':paths, 'dataset': 'SAVEE', \n",
        "                         'emotion':labels})\n",
        "df_savee[\"speaker\"] = df_savee[\"path\"].apply(lambda x:x[10:12])\n",
        "df_savee['augmented'] = False"
      ],
      "metadata": {
        "id": "Yg5P7mzaARZZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Audio Augmentation Functions\n",
        "def add_white_noise(signal, min_fac=0.1, max_fac=0.5):\n",
        "    noise_percentage_factor = random.uniform(min_fac, max_fac)\n",
        "    noise = np.random.normal(0, signal.std(), signal.size)\n",
        "    augmented_signal = signal + noise * noise_percentage_factor\n",
        "    return augmented_signal\n",
        "\n",
        "def time_stretch(signal, min_rt=0.9, max_rt=1.1):\n",
        "    time_stretch_rate = random.uniform(min_rt, max_rt)\n",
        "    return librosa.effects.time_stretch(signal, time_stretch_rate)\n",
        "\n",
        "def pitch_scale(signal, sr=22050, min_fac=-2, max_fac=2):\n",
        "    num_semitones = random.uniform(min_fac, max_fac)\n",
        "    return librosa.effects.pitch_shift(signal, sr, num_semitones)\n",
        "\n",
        "def random_gain(signal, min_factor=0.05, max_factor=0.12):\n",
        "    gain_rate = random.uniform(min_factor, max_factor)\n",
        "    augmented_signal = signal * gain_rate\n",
        "    return augmented_signal\n",
        "\n",
        "def invert_polarity(signal):\n",
        "    return signal * -1"
      ],
      "metadata": {
        "id": "d9rut3E3POr5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Audio Augmentation Process\n",
        "def aug_through_dataset(raw_df, sr, white_noise_only_prob, functions):\n",
        "  augmented_dataset = []\n",
        "  for data in raw_df.data:\n",
        "      if random.random() < white_noise_only_prob:\n",
        "          augmented_data = add_white_noise(data)\n",
        "      else:\n",
        "          num_functions = random.randint(1, len(functions))\n",
        "          selected_functions = random.sample(functions, num_functions)\n",
        "          augmented_data = data\n",
        "          for func in selected_functions:\n",
        "              augmented_data = func(augmented_data)\n",
        "      augmented_dataset.append(augmented_data)\n",
        "\n",
        "  aug_df = pd.DataFrame(columns=raw_df.columns)\n",
        "  aug_df['data'] = pd.Series(augmented_dataset)\n",
        "  for col in raw_df.columns:\n",
        "    if col == 'data':\n",
        "      aug_df[col] = pd.Series(augmented_dataset)\n",
        "    elif col == 'augmented':\n",
        "      aug_df[col] = True\n",
        "    else:\n",
        "      aug_df[col] = list(raw_df[col])\n",
        "  return aug_df"
      ],
      "metadata": {
        "id": "DTPNqLwXSjYm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Params for Data Augmentation\n",
        "random.seed(207) \n",
        "augmentation_num_loop = 3 # we have 4x480, nearly 2000 examples.\n",
        "functions = [add_white_noise, time_stretch, pitch_scale, random_gain, \n",
        "             invert_polarity]\n",
        "white_noise_only_prob = 0.2 # hard threshold for pitch adjustment.\n",
        "sr = 22050 # librosa default\n",
        "\n",
        "# === Start Augmentation\n",
        "augmented_df_list = []\n",
        "for i in range(augmentation_num_loop):\n",
        "  aug_df = aug_through_dataset(df_savee, sr, white_noise_only_prob, functions)\n",
        "  augmented_df_list.append(aug_df)\n",
        "\n",
        "final_df_savee = pd.concat(augmented_df_list, axis=0)\n",
        "final_df_savee = pd.concat([df_savee, final_df_savee], \n",
        "                           axis=0).reset_index(drop=True)\n",
        "print(final_df_savee.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMMP8oCfSlkc",
        "outputId": "678768e3-c59f-481a-a154-6bc7b477dd44"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                data                  path  \\\n",
            "0  [0.035011273, 0.052110124, 0.0455472, 0.049692...  AudioData/DC/a01.wav   \n",
            "1  [0.028584875, 0.043024283, 0.038623992, 0.0423...  AudioData/DC/a02.wav   \n",
            "2  [0.029121982, 0.043259364, 0.037821554, 0.0412...  AudioData/DC/a03.wav   \n",
            "3  [0.028819187, 0.042954646, 0.037683364, 0.0410...  AudioData/DC/a04.wav   \n",
            "4  [0.01032823, 0.015278679, 0.013250433, 0.01440...  AudioData/DC/a05.wav   \n",
            "\n",
            "  dataset emotion speaker  augmented  \n",
            "0   SAVEE       a      DC      False  \n",
            "1   SAVEE       a      DC      False  \n",
            "2   SAVEE       a      DC      False  \n",
            "3   SAVEE       a      DC      False  \n",
            "4   SAVEE       a      DC      False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Upload to GCloud\n",
        "np.save(file=\"augmented_dataset.npy\", arr=final_df_savee)\n",
        "final_df_savee.to_csv(\"augmented_dataset.csv\",index=False)\n",
        "blob = bucket.blob(\"augmented_dataset.npy\")\n",
        "blob.upload_from_filename(\"augmented_dataset.npy\")\n",
        "blob = bucket.blob(\"augmented_dataset.csv\")\n",
        "blob.upload_from_filename(\"augmented_dataset.csv\")"
      ],
      "metadata": {
        "id": "feJopHrLjzlw"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}